{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f1df5ba",
   "metadata": {},
   "source": [
    "### Tugas 1 Natural Language Processing\n",
    "\n",
    "13519038 - Ridho Daffasyah\n",
    "\n",
    "Deskripsi Tugas :\n",
    "\n",
    "Buatlah kode program penggunaan NLTK atau Spacy untuk:\n",
    "- Sentence splitter\n",
    "- Tokenization\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- Entity Masking\n",
    "- POS Tagger\n",
    "- Phrase Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2acd80e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##IMPORT LIBRARY\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "##Downloading resource from nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df166ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The series focuses on Luffy, a young man made of rubber, who, inspired by his childhood idol, the powerful pirate Red-Haired Shanks, sets off on a journey from the East Blue Sea to find the mythical treasure, the One Piece, and proclaim himself the King of the Pirates. In an effort to organize his own crew, the Straw Hat Pirates, Luffy rescues and befriends a pirate hunter and swordsman named Roronoa Zoro, and they head off in search of the titular treasure. \n"
     ]
    }
   ],
   "source": [
    "##GET TEXT FROM FILE TXT\n",
    "with open('One Piece.txt') as f:\n",
    "    contents = f.read()\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eaba01",
   "metadata": {},
   "source": [
    "### Step Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad50f390",
   "metadata": {},
   "source": [
    "### Lower Casing\n",
    "\n",
    "**Lower Casing** is converting a word to lower case (NLP -> nlp). Why? Because Words like Series and series mean the same but when not converted to the lower case those two are represented as two different words in the vector space model (resulting in more dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895aaad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the series focuses on luffy, a young man made of rubber, who, inspired by his childhood idol, the powerful pirate red-haired shanks, sets off on a journey from the east blue sea to find the mythical treasure, the one piece, and proclaim himself the king of the pirates. in an effort to organize his own crew, the straw hat pirates, luffy rescues and befriends a pirate hunter and swordsman named roronoa zoro, and they head off in search of the titular treasure. \n"
     ]
    }
   ],
   "source": [
    "def lower_casing(content):\n",
    "    lower_content = content.lower()\n",
    "    return lower_content\n",
    "\n",
    "lower_case_text = lower_casing(contents)\n",
    "print(lower_case_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585c4ca",
   "metadata": {},
   "source": [
    "### Sentence Splitter\n",
    "\n",
    "**Sentence Splitter** is the process of dividing text into sentences. For instance the document Hello world. Hello world again. would be split into the sentences Hello world. and Hello world again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd3ae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat ke-0 : the series focuses on luffy, a young man made of rubber, who, inspired by his childhood idol, the powerful pirate red-haired shanks, sets off on a journey from the east blue sea to find the mythical treasure, the one piece, and proclaim himself the king of the pirates.\n",
      "Kalimat ke-1 : in an effort to organize his own crew, the straw hat pirates, luffy rescues and befriends a pirate hunter and swordsman named roronoa zoro, and they head off in search of the titular treasure.\n"
     ]
    }
   ],
   "source": [
    "#SENT_TOKENIZE for splitting text into sentences\n",
    "def sentence_splitter(content):\n",
    "    tokenized_content = sent_tokenize(content)\n",
    "    return tokenized_content\n",
    "\n",
    "for i in range(len(sentence_splitter(lower_case_text))):\n",
    "    print(\"Kalimat ke-\" + str(i), \":\", sentence_splitter(lower_case_text)[i])\n",
    "    \n",
    "splitted_text = sentence_splitter(lower_case_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77593559",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "**Tokenization** is the process of dividing the text into tokens. Token is a series of characters that can be separated by spaces or punctuation marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff41619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kata ke-0 pada kalimat ke-0 : the\n",
      "Kata ke-1 pada kalimat ke-0 : series\n",
      "Kata ke-2 pada kalimat ke-0 : focuses\n",
      "Kata ke-3 pada kalimat ke-0 : on\n",
      "Kata ke-4 pada kalimat ke-0 : luffy\n",
      "Kata ke-5 pada kalimat ke-0 : ,\n",
      "Kata ke-6 pada kalimat ke-0 : a\n",
      "Kata ke-7 pada kalimat ke-0 : young\n",
      "Kata ke-8 pada kalimat ke-0 : man\n",
      "Kata ke-9 pada kalimat ke-0 : made\n",
      "Kata ke-10 pada kalimat ke-0 : of\n",
      "Kata ke-11 pada kalimat ke-0 : rubber\n",
      "Kata ke-12 pada kalimat ke-0 : ,\n",
      "Kata ke-13 pada kalimat ke-0 : who\n",
      "Kata ke-14 pada kalimat ke-0 : ,\n",
      "Kata ke-15 pada kalimat ke-0 : inspired\n",
      "Kata ke-16 pada kalimat ke-0 : by\n",
      "Kata ke-17 pada kalimat ke-0 : his\n",
      "Kata ke-18 pada kalimat ke-0 : childhood\n",
      "Kata ke-19 pada kalimat ke-0 : idol\n",
      "Kata ke-20 pada kalimat ke-0 : ,\n",
      "Kata ke-21 pada kalimat ke-0 : the\n",
      "Kata ke-22 pada kalimat ke-0 : powerful\n",
      "Kata ke-23 pada kalimat ke-0 : pirate\n",
      "Kata ke-24 pada kalimat ke-0 : red-haired\n",
      "Kata ke-25 pada kalimat ke-0 : shanks\n",
      "Kata ke-26 pada kalimat ke-0 : ,\n",
      "Kata ke-27 pada kalimat ke-0 : sets\n",
      "Kata ke-28 pada kalimat ke-0 : off\n",
      "Kata ke-29 pada kalimat ke-0 : on\n",
      "Kata ke-30 pada kalimat ke-0 : a\n",
      "Kata ke-31 pada kalimat ke-0 : journey\n",
      "Kata ke-32 pada kalimat ke-0 : from\n",
      "Kata ke-33 pada kalimat ke-0 : the\n",
      "Kata ke-34 pada kalimat ke-0 : east\n",
      "Kata ke-35 pada kalimat ke-0 : blue\n",
      "Kata ke-36 pada kalimat ke-0 : sea\n",
      "Kata ke-37 pada kalimat ke-0 : to\n",
      "Kata ke-38 pada kalimat ke-0 : find\n",
      "Kata ke-39 pada kalimat ke-0 : the\n",
      "Kata ke-40 pada kalimat ke-0 : mythical\n",
      "Kata ke-41 pada kalimat ke-0 : treasure\n",
      "Kata ke-42 pada kalimat ke-0 : ,\n",
      "Kata ke-43 pada kalimat ke-0 : the\n",
      "Kata ke-44 pada kalimat ke-0 : one\n",
      "Kata ke-45 pada kalimat ke-0 : piece\n",
      "Kata ke-46 pada kalimat ke-0 : ,\n",
      "Kata ke-47 pada kalimat ke-0 : and\n",
      "Kata ke-48 pada kalimat ke-0 : proclaim\n",
      "Kata ke-49 pada kalimat ke-0 : himself\n",
      "Kata ke-50 pada kalimat ke-0 : the\n",
      "Kata ke-51 pada kalimat ke-0 : king\n",
      "Kata ke-52 pada kalimat ke-0 : of\n",
      "Kata ke-53 pada kalimat ke-0 : the\n",
      "Kata ke-54 pada kalimat ke-0 : pirates\n",
      "Kata ke-55 pada kalimat ke-0 : .\n",
      "\n",
      "\n",
      "Kata ke-0 pada kalimat ke-1 : in\n",
      "Kata ke-1 pada kalimat ke-1 : an\n",
      "Kata ke-2 pada kalimat ke-1 : effort\n",
      "Kata ke-3 pada kalimat ke-1 : to\n",
      "Kata ke-4 pada kalimat ke-1 : organize\n",
      "Kata ke-5 pada kalimat ke-1 : his\n",
      "Kata ke-6 pada kalimat ke-1 : own\n",
      "Kata ke-7 pada kalimat ke-1 : crew\n",
      "Kata ke-8 pada kalimat ke-1 : ,\n",
      "Kata ke-9 pada kalimat ke-1 : the\n",
      "Kata ke-10 pada kalimat ke-1 : straw\n",
      "Kata ke-11 pada kalimat ke-1 : hat\n",
      "Kata ke-12 pada kalimat ke-1 : pirates\n",
      "Kata ke-13 pada kalimat ke-1 : ,\n",
      "Kata ke-14 pada kalimat ke-1 : luffy\n",
      "Kata ke-15 pada kalimat ke-1 : rescues\n",
      "Kata ke-16 pada kalimat ke-1 : and\n",
      "Kata ke-17 pada kalimat ke-1 : befriends\n",
      "Kata ke-18 pada kalimat ke-1 : a\n",
      "Kata ke-19 pada kalimat ke-1 : pirate\n",
      "Kata ke-20 pada kalimat ke-1 : hunter\n",
      "Kata ke-21 pada kalimat ke-1 : and\n",
      "Kata ke-22 pada kalimat ke-1 : swordsman\n",
      "Kata ke-23 pada kalimat ke-1 : named\n",
      "Kata ke-24 pada kalimat ke-1 : roronoa\n",
      "Kata ke-25 pada kalimat ke-1 : zoro\n",
      "Kata ke-26 pada kalimat ke-1 : ,\n",
      "Kata ke-27 pada kalimat ke-1 : and\n",
      "Kata ke-28 pada kalimat ke-1 : they\n",
      "Kata ke-29 pada kalimat ke-1 : head\n",
      "Kata ke-30 pada kalimat ke-1 : off\n",
      "Kata ke-31 pada kalimat ke-1 : in\n",
      "Kata ke-32 pada kalimat ke-1 : search\n",
      "Kata ke-33 pada kalimat ke-1 : of\n",
      "Kata ke-34 pada kalimat ke-1 : the\n",
      "Kata ke-35 pada kalimat ke-1 : titular\n",
      "Kata ke-36 pada kalimat ke-1 : treasure\n",
      "Kata ke-37 pada kalimat ke-1 : .\n"
     ]
    }
   ],
   "source": [
    "#WORD_TOKENIZE for splitting text into words\n",
    "def tokenization(content):\n",
    "    array_token = []\n",
    "    for token in content: \n",
    "        array_token.append(word_tokenize(token))\n",
    "    return array_token\n",
    "\n",
    "for i in range(len(tokenization(splitted_text))):\n",
    "    if (i == 1):\n",
    "        print(\"\\n\")\n",
    "    for j in range(len(tokenization(splitted_text)[i])):\n",
    "        print(\"Kata ke-\" + str(j), \"pada kalimat ke-\" + str(i), \":\", tokenization(splitted_text)[i][j])\n",
    "\n",
    "tokenize_1 = tokenization(splitted_text)[0]\n",
    "tokenize_2 = tokenization(splitted_text)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cc3ba9",
   "metadata": {},
   "source": [
    "### Stop Words\n",
    "\n",
    "**Stop Words** are very commonly used words (a, an, the, etc.) in the documents. These words do not really signify any importance as they do not help in distinguishing two documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8de0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kata ke-0 : series\n",
      "Kata ke-1 : focuses\n",
      "Kata ke-2 : luffy\n",
      "Kata ke-3 : ,\n",
      "Kata ke-4 : young\n",
      "Kata ke-5 : man\n",
      "Kata ke-6 : made\n",
      "Kata ke-7 : rubber\n",
      "Kata ke-8 : ,\n",
      "Kata ke-9 : ,\n",
      "Kata ke-10 : inspired\n",
      "Kata ke-11 : childhood\n",
      "Kata ke-12 : idol\n",
      "Kata ke-13 : ,\n",
      "Kata ke-14 : powerful\n",
      "Kata ke-15 : pirate\n",
      "Kata ke-16 : red-haired\n",
      "Kata ke-17 : shanks\n",
      "Kata ke-18 : ,\n",
      "Kata ke-19 : sets\n",
      "Kata ke-20 : journey\n",
      "Kata ke-21 : east\n",
      "Kata ke-22 : blue\n",
      "Kata ke-23 : sea\n",
      "Kata ke-24 : find\n",
      "Kata ke-25 : mythical\n",
      "Kata ke-26 : treasure\n",
      "Kata ke-27 : ,\n",
      "Kata ke-28 : one\n",
      "Kata ke-29 : piece\n",
      "Kata ke-30 : ,\n",
      "Kata ke-31 : proclaim\n",
      "Kata ke-32 : king\n",
      "Kata ke-33 : pirates\n",
      "Kata ke-34 : .\n",
      "\n",
      "\n",
      "Kata ke-0 : effort\n",
      "Kata ke-1 : organize\n",
      "Kata ke-2 : crew\n",
      "Kata ke-3 : ,\n",
      "Kata ke-4 : straw\n",
      "Kata ke-5 : hat\n",
      "Kata ke-6 : pirates\n",
      "Kata ke-7 : ,\n",
      "Kata ke-8 : luffy\n",
      "Kata ke-9 : rescues\n",
      "Kata ke-10 : befriends\n",
      "Kata ke-11 : pirate\n",
      "Kata ke-12 : hunter\n",
      "Kata ke-13 : swordsman\n",
      "Kata ke-14 : named\n",
      "Kata ke-15 : roronoa\n",
      "Kata ke-16 : zoro\n",
      "Kata ke-17 : ,\n",
      "Kata ke-18 : head\n",
      "Kata ke-19 : search\n",
      "Kata ke-20 : titular\n",
      "Kata ke-21 : treasure\n",
      "Kata ke-22 : .\n"
     ]
    }
   ],
   "source": [
    "#STOPWORDS\n",
    "def stop_words(content):\n",
    "    stop_word = set(stopwords.words('english'))\n",
    "    array_clear_word = []\n",
    "    for word in content: \n",
    "        if word not in stop_word:\n",
    "            array_clear_word.append(word)\n",
    "    return array_clear_word\n",
    "\n",
    "clear_word_1 = stop_words(tokenize_1)\n",
    "clear_word_2 = stop_words(tokenize_2)\n",
    "\n",
    "for i in range(len(clear_word_1)):\n",
    "    print(\"Kata ke-\" + str(i), \":\", clear_word_1[i])\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "for i in range(len(clear_word_2)):\n",
    "    print(\"Kata ke-\" + str(i), \":\", clear_word_2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6c81b6",
   "metadata": {},
   "source": [
    "### Removing Punctuations\n",
    "\n",
    "**Punctuations** are likes \",\" \".\", etc. We must remove because the punctuations present in the text do not add value to the data. The punctuation, when attached to any word, will create a problem in differentiating with other words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ac2169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kata ke-0 : series\n",
      "Kata ke-1 : focuses\n",
      "Kata ke-2 : luffy\n",
      "Kata ke-3 : young\n",
      "Kata ke-4 : man\n",
      "Kata ke-5 : made\n",
      "Kata ke-6 : rubber\n",
      "Kata ke-7 : inspired\n",
      "Kata ke-8 : childhood\n",
      "Kata ke-9 : idol\n",
      "Kata ke-10 : powerful\n",
      "Kata ke-11 : pirate\n",
      "Kata ke-12 : red-haired\n",
      "Kata ke-13 : shanks\n",
      "Kata ke-14 : sets\n",
      "Kata ke-15 : journey\n",
      "Kata ke-16 : east\n",
      "Kata ke-17 : blue\n",
      "Kata ke-18 : sea\n",
      "Kata ke-19 : find\n",
      "Kata ke-20 : mythical\n",
      "Kata ke-21 : treasure\n",
      "Kata ke-22 : one\n",
      "Kata ke-23 : piece\n",
      "Kata ke-24 : proclaim\n",
      "Kata ke-25 : king\n",
      "Kata ke-26 : pirates\n",
      "\n",
      "\n",
      "Kata ke-0 : effort\n",
      "Kata ke-1 : organize\n",
      "Kata ke-2 : crew\n",
      "Kata ke-3 : straw\n",
      "Kata ke-4 : hat\n",
      "Kata ke-5 : pirates\n",
      "Kata ke-6 : luffy\n",
      "Kata ke-7 : rescues\n",
      "Kata ke-8 : befriends\n",
      "Kata ke-9 : pirate\n",
      "Kata ke-10 : hunter\n",
      "Kata ke-11 : swordsman\n",
      "Kata ke-12 : named\n",
      "Kata ke-13 : roronoa\n",
      "Kata ke-14 : zoro\n",
      "Kata ke-15 : head\n",
      "Kata ke-16 : search\n",
      "Kata ke-17 : titular\n",
      "Kata ke-18 : treasure\n"
     ]
    }
   ],
   "source": [
    "#PUNCTUATIONS\n",
    "def remove_punctuations(content):\n",
    "    array_clear_word = []\n",
    "    for word in content: \n",
    "        if word not in string.punctuation:\n",
    "            array_clear_word.append(word)\n",
    "    return array_clear_word\n",
    "\n",
    "clear_array_1 = remove_punctuations(clear_word_1)\n",
    "clear_array_2 = remove_punctuations(clear_word_2)\n",
    "\n",
    "for i in range(len(clear_array_1)):\n",
    "    print(\"Kata ke-\" + str(i), \":\", clear_array_1[i])\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "for i in range(len(clear_array_2)):\n",
    "    print(\"Kata ke-\" + str(i), \":\", clear_array_2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bcb976",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "\n",
    "**Stemming** is the process of reducing the word to its word stem that affixes to suffixes and prefixes or to roots of words known as a lemma. In simple words stemming is reducing a word to its base word or stem in such a way that the words of similar kind lie under a common stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4bc1759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kata ke-0 : seri\n",
      "Kata ke-1 : focus\n",
      "Kata ke-2 : luffi\n",
      "Kata ke-3 : young\n",
      "Kata ke-4 : man\n",
      "Kata ke-5 : made\n",
      "Kata ke-6 : rubber\n",
      "Kata ke-7 : inspir\n",
      "Kata ke-8 : childhood\n",
      "Kata ke-9 : idol\n",
      "Kata ke-10 : power\n",
      "Kata ke-11 : pirat\n",
      "Kata ke-12 : red-hair\n",
      "Kata ke-13 : shank\n",
      "Kata ke-14 : set\n",
      "Kata ke-15 : journey\n",
      "Kata ke-16 : east\n",
      "Kata ke-17 : blue\n",
      "Kata ke-18 : sea\n",
      "Kata ke-19 : find\n",
      "Kata ke-20 : mythic\n",
      "Kata ke-21 : treasur\n",
      "Kata ke-22 : one\n",
      "Kata ke-23 : piec\n",
      "Kata ke-24 : proclaim\n",
      "Kata ke-25 : king\n",
      "Kata ke-26 : pirat\n",
      "\n",
      "\n",
      "Kata ke-0 : effort\n",
      "Kata ke-1 : organ\n",
      "Kata ke-2 : crew\n",
      "Kata ke-3 : straw\n",
      "Kata ke-4 : hat\n",
      "Kata ke-5 : pirat\n",
      "Kata ke-6 : luffi\n",
      "Kata ke-7 : rescu\n",
      "Kata ke-8 : befriend\n",
      "Kata ke-9 : pirat\n",
      "Kata ke-10 : hunter\n",
      "Kata ke-11 : swordsman\n",
      "Kata ke-12 : name\n",
      "Kata ke-13 : roronoa\n",
      "Kata ke-14 : zoro\n",
      "Kata ke-15 : head\n",
      "Kata ke-16 : search\n",
      "Kata ke-17 : titular\n",
      "Kata ke-18 : treasur\n"
     ]
    }
   ],
   "source": [
    "#STEMMING\n",
    "def stemming(content):\n",
    "    stemmer = PorterStemmer()\n",
    "    #stem's of each word\n",
    "    stem_words = []\n",
    "    for word in content:\n",
    "        x = stemmer.stem(word)\n",
    "        stem_words.append(x)\n",
    "    return stem_words\n",
    "\n",
    "stem_1 = stemming(clear_array_1)\n",
    "stem_2 = stemming(clear_array_2)\n",
    "\n",
    "for i in range(len(stem_1)):\n",
    "    print(\"Kata ke-\" + str(i), \":\", stem_1[i])\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "for i in range(len(stem_2)):\n",
    "    print(\"Kata ke-\" + str(i), \":\", stem_2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8be90c",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "**Lemmatization** is a technique that switches any kind of a word to its base root mode. Lemmatization is responsible for grouping different inflected forms of words into the root form, having the same meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a945548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kata ke-0 : series\n",
      "Kata ke-1 : focus\n",
      "Kata ke-2 : luffy\n",
      "Kata ke-3 : young\n",
      "Kata ke-4 : man\n",
      "Kata ke-5 : made\n",
      "Kata ke-6 : rubber\n",
      "Kata ke-7 : inspired\n",
      "Kata ke-8 : childhood\n",
      "Kata ke-9 : idol\n",
      "Kata ke-10 : powerful\n",
      "Kata ke-11 : pirate\n",
      "Kata ke-12 : red-haired\n",
      "Kata ke-13 : shank\n",
      "Kata ke-14 : set\n",
      "Kata ke-15 : journey\n",
      "Kata ke-16 : east\n",
      "Kata ke-17 : blue\n",
      "Kata ke-18 : sea\n",
      "Kata ke-19 : find\n",
      "Kata ke-20 : mythical\n",
      "Kata ke-21 : treasure\n",
      "Kata ke-22 : one\n",
      "Kata ke-23 : piece\n",
      "Kata ke-24 : proclaim\n",
      "Kata ke-25 : king\n",
      "Kata ke-26 : pirate\n",
      "\n",
      "\n",
      "Kata ke-0 : effort\n",
      "Kata ke-1 : organize\n",
      "Kata ke-2 : crew\n",
      "Kata ke-3 : straw\n",
      "Kata ke-4 : hat\n",
      "Kata ke-5 : pirate\n",
      "Kata ke-6 : luffy\n",
      "Kata ke-7 : rescue\n",
      "Kata ke-8 : befriends\n",
      "Kata ke-9 : pirate\n",
      "Kata ke-10 : hunter\n",
      "Kata ke-11 : swordsman\n",
      "Kata ke-12 : named\n",
      "Kata ke-13 : roronoa\n",
      "Kata ke-14 : zoro\n",
      "Kata ke-15 : head\n",
      "Kata ke-16 : search\n",
      "Kata ke-17 : titular\n",
      "Kata ke-18 : treasure\n"
     ]
    }
   ],
   "source": [
    "#LEMMATIZATION\n",
    "def lemmatization(content):\n",
    "    lem = WordNetLemmatizer()\n",
    "    #stem's of each word\n",
    "    lem_words = []\n",
    "    for word in content:\n",
    "        x = lem.lemmatize(word)\n",
    "        lem_words.append(x)\n",
    "    return lem_words\n",
    "\n",
    "lem_1 = lemmatization(clear_array_1)\n",
    "lem_2 = lemmatization(clear_array_2)\n",
    "\n",
    "for i in range(len(lem_1)):\n",
    "    print(\"Kata ke-\" + str(i), \":\", lem_1[i])\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "for i in range(len(lem_2)):\n",
    "    print(\"Kata ke-\" + str(i), \":\", lem_2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605a0ae",
   "metadata": {},
   "source": [
    "### Entity Masking\n",
    "\n",
    "**Entity Masking** is masking the text that is represented to entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5581351e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kata ke-0 : series\n",
      "Kata ke-1 : focus\n",
      "Kata ke-2 : _name_\n",
      "Kata ke-3 : young\n",
      "Kata ke-4 : man\n",
      "Kata ke-5 : made\n",
      "Kata ke-6 : rubber\n",
      "Kata ke-7 : inspired\n",
      "Kata ke-8 : childhood\n",
      "Kata ke-9 : idol\n",
      "Kata ke-10 : powerful\n",
      "Kata ke-11 : pirate\n",
      "Kata ke-12 : red-haired\n",
      "Kata ke-13 : shank\n",
      "Kata ke-14 : set\n",
      "Kata ke-15 : journey\n",
      "Kata ke-16 : east\n",
      "Kata ke-17 : blue\n",
      "Kata ke-18 : sea\n",
      "Kata ke-19 : find\n",
      "Kata ke-20 : mythical\n",
      "Kata ke-21 : treasure\n",
      "Kata ke-22 : one\n",
      "Kata ke-23 : piece\n",
      "Kata ke-24 : proclaim\n",
      "Kata ke-25 : king\n",
      "Kata ke-26 : pirate\n",
      "\n",
      "\n",
      "Kata ke-0 : effort\n",
      "Kata ke-1 : organize\n",
      "Kata ke-2 : crew\n",
      "Kata ke-3 : straw\n",
      "Kata ke-4 : hat\n",
      "Kata ke-5 : pirate\n",
      "Kata ke-6 : _name_\n",
      "Kata ke-7 : rescue\n",
      "Kata ke-8 : befriends\n",
      "Kata ke-9 : pirate\n",
      "Kata ke-10 : hunter\n",
      "Kata ke-11 : swordsman\n",
      "Kata ke-12 : named\n",
      "Kata ke-13 : _name_\n",
      "Kata ke-14 : _name_\n",
      "Kata ke-15 : head\n",
      "Kata ke-16 : search\n",
      "Kata ke-17 : titular\n",
      "Kata ke-18 : treasure\n"
     ]
    }
   ],
   "source": [
    "#ENTITYMASKING\n",
    "def entity_masking(content):\n",
    "    name = re.compile(r\"(luffy|roronoa|zoro)\")\n",
    "    masked_array = []\n",
    "    for word in content: \n",
    "        masked_array.append(name.sub(\"_name_\", word))\n",
    "    return masked_array\n",
    "\n",
    "masked_1 = entity_masking(lem_1)\n",
    "masked_2 = entity_masking(lem_2)\n",
    "\n",
    "for i in range(len(masked_1)):\n",
    "    print(\"Kata ke-\" + str(i), \":\", masked_1[i])\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "for i in range(len(masked_2)):\n",
    "    print(\"Kata ke-\" + str(i), \":\", masked_2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5764e5",
   "metadata": {},
   "source": [
    "### POS Tagger\n",
    "\n",
    "**POS Tagger** is a tool to tag POS of each word in the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61f7f37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kata ke-0 : ('series', 'NN')\n",
      "Kata ke-1 : ('focus', 'NN')\n",
      "Kata ke-2 : ('_name_', 'NNP')\n",
      "Kata ke-3 : ('young', 'JJ')\n",
      "Kata ke-4 : ('man', 'NN')\n",
      "Kata ke-5 : ('made', 'VBD')\n",
      "Kata ke-6 : ('rubber', 'NN')\n",
      "Kata ke-7 : ('inspired', 'JJ')\n",
      "Kata ke-8 : ('childhood', 'NN')\n",
      "Kata ke-9 : ('idol', 'NN')\n",
      "Kata ke-10 : ('powerful', 'JJ')\n",
      "Kata ke-11 : ('pirate', 'JJ')\n",
      "Kata ke-12 : ('red-haired', 'JJ')\n",
      "Kata ke-13 : ('shank', 'NN')\n",
      "Kata ke-14 : ('set', 'VBN')\n",
      "Kata ke-15 : ('journey', 'NN')\n",
      "Kata ke-16 : ('east', 'JJ')\n",
      "Kata ke-17 : ('blue', 'JJ')\n",
      "Kata ke-18 : ('sea', 'NN')\n",
      "Kata ke-19 : ('find', 'VB')\n",
      "Kata ke-20 : ('mythical', 'JJ')\n",
      "Kata ke-21 : ('treasure', 'NN')\n",
      "Kata ke-22 : ('one', 'CD')\n",
      "Kata ke-23 : ('piece', 'NN')\n",
      "Kata ke-24 : ('proclaim', 'NN')\n",
      "Kata ke-25 : ('king', 'VBG')\n",
      "Kata ke-26 : ('pirate', 'NN')\n",
      "\n",
      "\n",
      "Kata ke-0 : ('effort', 'NN')\n",
      "Kata ke-1 : ('organize', 'VB')\n",
      "Kata ke-2 : ('crew', 'JJ')\n",
      "Kata ke-3 : ('straw', 'JJ')\n",
      "Kata ke-4 : ('hat', 'WP')\n",
      "Kata ke-5 : ('pirate', 'VBP')\n",
      "Kata ke-6 : ('_name_', 'NNS')\n",
      "Kata ke-7 : ('rescue', 'VB')\n",
      "Kata ke-8 : ('befriends', 'NNS')\n",
      "Kata ke-9 : ('pirate', 'JJ')\n",
      "Kata ke-10 : ('hunter', 'NN')\n",
      "Kata ke-11 : ('swordsman', 'NN')\n",
      "Kata ke-12 : ('named', 'VBN')\n",
      "Kata ke-13 : ('_name_', 'NNP')\n",
      "Kata ke-14 : ('_name_', 'NNP')\n",
      "Kata ke-15 : ('head', 'NN')\n",
      "Kata ke-16 : ('search', 'NN')\n",
      "Kata ke-17 : ('titular', 'JJ')\n",
      "Kata ke-18 : ('treasure', 'NN')\n"
     ]
    }
   ],
   "source": [
    "#POSTAGGER\n",
    "def pos_tagger(content):\n",
    "    tag = nltk.pos_tag(content)\n",
    "    return tag\n",
    "\n",
    "tag_1 = pos_tagger(masked_1)\n",
    "tag_2 = pos_tagger(masked_2)\n",
    "\n",
    "for i in range(len(tag_1)):\n",
    "    print(\"Kata ke-\" + str(i), \":\", tag_1[i])\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "for i in range(len(tag_2)):\n",
    "    print(\"Kata ke-\" + str(i), \":\", tag_2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e273255",
   "metadata": {},
   "source": [
    "### Phrase Chunker\n",
    "\n",
    "**Phrase Chunker** is to chunk a certain phrase with given text pattern and the process of natural language processing used to identify parts of speech and short phrases present in a given sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eb79318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree chunk 1 : \n",
      "(S\n",
      "  (NP series/NN)\n",
      "  (NP focus/NN)\n",
      "  _name_/NNP\n",
      "  (NP young/JJ man/NN)\n",
      "  made/VBD\n",
      "  (NP rubber/NN)\n",
      "  (NP inspired/JJ childhood/NN)\n",
      "  (NP idol/NN)\n",
      "  (NP powerful/JJ pirate/JJ red-haired/JJ shank/NN)\n",
      "  set/VBN\n",
      "  (NP journey/NN)\n",
      "  (NP east/JJ blue/JJ sea/NN)\n",
      "  find/VB\n",
      "  (NP mythical/JJ treasure/NN)\n",
      "  one/CD\n",
      "  (NP piece/NN)\n",
      "  (NP proclaim/NN)\n",
      "  king/VBG\n",
      "  (NP pirate/NN)) \n",
      "\n",
      "Tree chunk 2 : \n",
      "(S\n",
      "  (NP effort/NN)\n",
      "  organize/VB\n",
      "  crew/JJ\n",
      "  straw/JJ\n",
      "  hat/WP\n",
      "  pirate/VBP\n",
      "  _name_/NNS\n",
      "  rescue/VB\n",
      "  befriends/NNS\n",
      "  (NP pirate/JJ hunter/NN)\n",
      "  (NP swordsman/NN)\n",
      "  named/VBN\n",
      "  _name_/NNP\n",
      "  _name_/NNP\n",
      "  (NP head/NN)\n",
      "  (NP search/NN)\n",
      "  (NP titular/JJ treasure/NN))\n"
     ]
    }
   ],
   "source": [
    "#Phrasechunking\n",
    "def phrase_chunk(content):\n",
    "    pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
    "    cp = nltk.RegexpParser(pattern)\n",
    "    cs = cp.parse(content)\n",
    "    return cs\n",
    "\n",
    "print(\"Tree chunk 1 : \")\n",
    "print(phrase_chunk(tag_1), \"\\n\")\n",
    "\n",
    "print(\"Tree chunk 2 : \")\n",
    "print(phrase_chunk(tag_2))\n",
    "\n",
    "phrase_chunk(tag_1).draw()\n",
    "phrase_chunk(tag_1).draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
